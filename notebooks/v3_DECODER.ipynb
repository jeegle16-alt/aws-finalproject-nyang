{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Decoder v3: Risk Score ‚Üí Cat State\n",
    "\n",
    "**Î™©Ï†Å**: MODEL Ï∂úÎ†•(risk_score)ÏùÑ ÏÇ¨Ïö©ÏûêÍ∞Ä Î≥¥Îäî Í≥†ÏñëÏù¥ ÏÉÅÌÉúÎ°ú Î≥ÄÌôò\n",
    "\n",
    "**ÏûÖÎ†•**: `model_out_v3.csv`  \n",
    "**Ï∂úÎ†•**: `state_out_v3.csv`\n",
    "\n",
    "**Cat States**:\n",
    "- üò∫ STABLE: ÏïàÏ†ï\n",
    "- üò¥ SLEEP: ÏàòÎ©¥ Ìå®ÌÑ¥ Î≥ÄÌôî\n",
    "- üòæ LETHARGY: Î¨¥Í∏∞Î†•\n",
    "- üòµ CHAOS: ÌòºÎûÄ\n",
    "- üß≥ TRAVEL: Ïó¨Ìñâ/Ïù¥Îèô\n",
    "- ‚ö´ NO_DATA: Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±\n",
    "\n",
    "**CRITICAL (üö®)ÏùÄ Î∞±ÏóîÎìúÍ∞Ä RDSÏóê ÏßÅÏ†ë ÏîÄ - MLÏùÄ ÌåêÏ†ïÌïòÏßÄ ÏïäÏùå**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section0",
   "metadata": {},
   "source": [
    "# 0. ÌôòÍ≤Ω ÏÑ§Ï†ï & Í∞úÏöî"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section0_1",
   "metadata": {},
   "source": [
    "## 0.1 ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section0_2",
   "metadata": {},
   "source": [
    "## 0.2 ÎîîÏΩîÎçî Ï±ÖÏûÑ Î≤îÏúÑ\n",
    "\n",
    "**DECODERÏùò Ïó≠Ìï†**:\n",
    "1. risk_scoreÎ•º ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†Å ÏÉÅÌÉúÎ°ú Î≥ÄÌôò\n",
    "2. Top-Z feature Í∏∞Î∞ò ÏÉÅÌÉú Ìï¥ÏÑù (SLEEP/LETHARGY/CHAOS)\n",
    "3. Context Î∞òÏòÅ (TRAVEL)\n",
    "4. Notification level Í≤∞Ï†ï\n",
    "\n",
    "**ÌïòÏßÄ ÏïäÎäî Í≤É**:\n",
    "- CRITICAL ÌåêÏ†ï (Î∞±ÏóîÎìúÍ∞Ä RDSÏóê ÏßÅÏ†ë ÏîÄ)\n",
    "- Risk Í≥ÑÏÇ∞ (MODELÏù¥ Ìï®)\n",
    "- QC ÌåêÏ†ï (FEÍ∞Ä Ìï®)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section0_3",
   "metadata": {},
   "source": [
    "## 0.3 ÏÉÅÏàò Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constants",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Constants defined\n",
      "Risk thresholds: LOW=0.45, ALERT=0.6, SEV=0.7\n"
     ]
    }
   ],
   "source": [
    "# === Risk Thresholds ===\n",
    "# risk_score Î∂ÑÌè¨ Í∏∞Î∞ò ÏûÑÍ≥ÑÍ∞í (MODELÏóêÏÑú p90/p95/p99)\n",
    "RISK_LOW = 0.45      # p90 Í∑ºÏ≤ò (ÏïàÏ†ï)\n",
    "RISK_ALERT = 0.60    # p95 Í∑ºÏ≤ò (Ï£ºÏùò)\n",
    "RISK_SEVERE = 0.70   # p99 Í∑ºÏ≤ò (Í≤ΩÍ≥†)\n",
    "\n",
    "# === State Priority ===\n",
    "# Ïó¨Îü¨ Ï°∞Í±¥ Ï∂©Ï°± Ïãú Ïö∞ÏÑ†ÏàúÏúÑ (ÎÜíÏùÑÏàòÎ°ù Ïö∞ÏÑ†)\n",
    "STATE_PRIORITY = {\n",
    "    'NO_DATA': 100,\n",
    "    'TRAVEL': 90,\n",
    "    'CHAOS': 70,\n",
    "    'LETHARGY': 60,\n",
    "    'SLEEP': 50,\n",
    "    'STABLE': 10,\n",
    "}\n",
    "\n",
    "# === Top-Z Feature Groups ===\n",
    "SLEEP_FEATURES = ['night_ratio_z', 'overnight_gap_z']\n",
    "LETHARGY_FEATURES = ['daily_event_cnt_z', 'UserAct_z', 'Screen_z']\n",
    "CHAOS_FEATURES = ['hour_entropy_z', 'gap_max_z', 'gap_cnt_6h_z']\n",
    "\n",
    "# === Z-score Threshold ===\n",
    "# Top-Z ÌåêÏ†ï Í∏∞Ï§Ä (Ï†àÎåìÍ∞í)\n",
    "Z_THRESHOLD = 2.0  # |z| >= 2.0 Ïù¥Î©¥ Ïú†ÏùòÎØ∏\n",
    "\n",
    "# [v3] Í∑∏Î£πÎ≥Ñ ÎåÄÌëú Z Ïª¨Îüº (MODELÏóêÏÑú export)\n",
    "GROUP_REP_MAP = {\n",
    "    \"rhythm\": \"z_rhythm_rep\",   # SLEEP ÌåêÏ†ïÏö©\n",
    "    \"core\":   \"z_core_rep\",     # LETHARGY ÌåêÏ†ïÏö©\n",
    "    \"gap\":    \"z_gap_rep\",      # CHAOS ÌåêÏ†ïÏö©\n",
    "    \"session\":\"z_session_rep\",  # Î≥¥Ï°∞\n",
    "}\n",
    "GROUP_Z_THRESHOLD = 1.5  # Í∑∏Î£π ÎåÄÌëúÍ∞í Í∏∞Ï§Ä (Í∞úÎ≥Ñ ÌîºÏ≤òÎ≥¥Îã§ ÎÇÆÍ≤å)\n",
    "\n",
    "# === Cold-Start Stages ===\n",
    "STAGE_NOTIFY_MAP = {\n",
    "    'ONBOARD': 'NONE',      # 1-4Ïùº: ÏïåÎ¶º ÏóÜÏùå\n",
    "    'WARMUP': 'NONE',       # 5-8Ïùº: ÏïåÎ¶º ÏóÜÏùå\n",
    "    'SEMI_READY': 'LOW',    # 9-15Ïùº: ÎÇÆÏùÄ ÏïåÎ¶ºÎßå\n",
    "    'READY': 'NORMAL',      # 16Ïùº~: Ï†ïÏÉÅ ÏïåÎ¶º\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Constants defined\")\n",
    "print(f\"Risk thresholds: LOW={RISK_LOW}, ALERT={RISK_ALERT}, SEV={RISK_SEVERE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú & Ïä§ÌÇ§Îßà Í≤ÄÏ¶ù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1_1",
   "metadata": {},
   "source": [
    "## 1.1 model_out_v3.csv Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded: ..\\artifacts\\model\\model_out_v3.csv\n",
      "Rows: 9,057 | Users: 342\n",
      "Columns: 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>date</th>\n",
       "      <th>day_idx</th>\n",
       "      <th>cold_stage</th>\n",
       "      <th>early_ready</th>\n",
       "      <th>early_risk</th>\n",
       "      <th>final_risk</th>\n",
       "      <th>quality_state</th>\n",
       "      <th>context_mode</th>\n",
       "      <th>baseline_ready</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_cnt_2h_z</th>\n",
       "      <th>gap_cnt_6h_z</th>\n",
       "      <th>gap_long_ratio_z</th>\n",
       "      <th>overnight_gap_z</th>\n",
       "      <th>daily_event_cnt_drift_z</th>\n",
       "      <th>night_ratio_drift_z</th>\n",
       "      <th>gap_max_drift_z</th>\n",
       "      <th>z_core_rep</th>\n",
       "      <th>z_rhythm_rep</th>\n",
       "      <th>z_gap_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>1</td>\n",
       "      <td>ONBOARD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>2</td>\n",
       "      <td>ONBOARD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>3</td>\n",
       "      <td>ONBOARD</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid       date  day_idx cold_stage  early_ready  early_risk  \\\n",
       "0  u072142 2016-06-19        1    ONBOARD        False         NaN   \n",
       "1  u072142 2016-06-20        2    ONBOARD        False         NaN   \n",
       "2  u072142 2016-06-21        3    ONBOARD        False         NaN   \n",
       "\n",
       "   final_risk quality_state context_mode  baseline_ready  ...  gap_cnt_2h_z  \\\n",
       "0         NaN          GOOD       NORMAL           False  ...           NaN   \n",
       "1         NaN          GOOD       NORMAL           False  ...           NaN   \n",
       "2         NaN          GOOD       NORMAL           False  ...           NaN   \n",
       "\n",
       "   gap_cnt_6h_z  gap_long_ratio_z  overnight_gap_z  daily_event_cnt_drift_z  \\\n",
       "0           NaN               NaN              NaN                      NaN   \n",
       "1           NaN               NaN              NaN                      NaN   \n",
       "2           NaN               NaN              NaN                      NaN   \n",
       "\n",
       "   night_ratio_drift_z  gap_max_drift_z z_core_rep  z_rhythm_rep  z_gap_rep  \n",
       "0                  NaN              NaN        NaN           NaN        NaN  \n",
       "1                  NaN              NaN        NaN           NaN        NaN  \n",
       "2                  NaN              NaN        NaN           NaN        NaN  \n",
       "\n",
       "[3 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = Path(\"../artifacts/model/model_out_v3.csv\")\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model output not found: {MODEL_PATH}\")\n",
    "\n",
    "df = pd.read_csv(MODEL_PATH)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"‚úÖ Loaded: {MODEL_PATH}\")\n",
    "print(f\"Rows: {len(df):,} | Users: {df['uuid'].nunique()}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1_2",
   "metadata": {},
   "source": [
    "## 1.2 ÌïÑÏàò Ïª¨Îüº Ï°¥Ïû¨ Ï≤¥ÌÅ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "schema_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema OK\n",
      "Z-score columns: 15\n",
      "Examples: ['daily_event_cnt_z', 'Screen_z', 'Notif_z', 'UserAct_z', 'night_ratio_z']\n"
     ]
    }
   ],
   "source": [
    "REQUIRED_COLS = [\n",
    "    \"uuid\", \"date\",\n",
    "    # risk\n",
    "    \"risk_score\",            # ÏµúÏÜå\n",
    "    # quality/context\n",
    "    \"quality_state\",\n",
    "    \"cold_stage\",\n",
    "    \"travel_flag\",\n",
    "]\n",
    "\n",
    "missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# ---- optional columns: ÏóÜÏúºÎ©¥ default ÏÉùÏÑ± (Ïö¥ÏòÅ ÏïàÏ†ïÏÑ±)\n",
    "OPTIONAL_DEFAULTS = {\n",
    "    \"final_risk\": np.nan,        # ÏûàÏúºÎ©¥ risk_used Ïö∞ÏÑ†\n",
    "    \"early_risk\": np.nan,\n",
    "    \"baseline_ready\": False,\n",
    "    \"early_ready\": False,\n",
    "    \"has_activity\": False,\n",
    "\n",
    "    # context flags (ÏûàÏúºÎ©¥ downshiftÏóê ÏÇ¨Ïö©)\n",
    "    \"partial_flag\": False,\n",
    "    \"tz_flag\": False,\n",
    "\n",
    "    # recovery flags (MODELÏóêÏÑú ÏÉùÏÑ±)\n",
    "    \"stable_hold_flag\": False,\n",
    "    \"drift_flag\": False,\n",
    "    \"drift_top_feature\": \"\",\n",
    "}\n",
    "for c, v in OPTIONAL_DEFAULTS.items():\n",
    "    if c not in df.columns:\n",
    "        df[c] = v\n",
    "\n",
    "# Z-score Ïª¨Îüº ÌôïÏù∏\n",
    "z_cols = [c for c in df.columns if c.endswith(\"_z\") and not c.endswith(\"_z_early\")]\n",
    "print(\"‚úÖ Schema OK\")\n",
    "print(f\"Z-score columns: {len(z_cols)}\")\n",
    "print(f\"Examples: {z_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1_3",
   "metadata": {},
   "source": [
    "## 1.3 Ïª¨Îüº ÌÉÄÏûÖ ÌëúÏ§ÄÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "type_normalize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Type normalization done\n",
      "risk_used valid: 7,352 / 9,057\n",
      "quality_state dist: {'GOOD': 8702, 'LOW_CONF': 355}\n"
     ]
    }
   ],
   "source": [
    "df = df.copy()\n",
    "\n",
    "# Boolean ÌîåÎûòÍ∑∏(ÏóÜÏúºÎ©¥ Ïù¥ÎØ∏ default ÏÉùÏÑ±Îê®)\n",
    "BOOL_COLS = [\"travel_flag\", \"partial_flag\", \"tz_flag\", \"baseline_ready\", \"early_ready\", \"has_activity\", \"stable_hold_flag\", \"drift_flag\"]\n",
    "for c in BOOL_COLS:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"boolean\").fillna(False)\n",
    "\n",
    "# Numeric\n",
    "for c in [\"risk_score\", \"final_risk\", \"early_risk\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# String\n",
    "for c in [\"quality_state\", \"context_mode\", \"cold_stage\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"string\")\n",
    "\n",
    "# ‚úÖ ÌïµÏã¨: risk_used ÌÜµÏùº (final_risk Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ risk_score)\n",
    "df[\"risk_used\"] = df[\"final_risk\"]\n",
    "df.loc[df[\"risk_used\"].isna(), \"risk_used\"] = df.loc[df[\"risk_used\"].isna(), \"risk_score\"]\n",
    "\n",
    "print(\"‚úÖ Type normalization done\")\n",
    "print(f\"risk_used valid: {df['risk_used'].notna().sum():,} / {len(df):,}\")\n",
    "print(f\"quality_state dist: {df['quality_state'].value_counts(dropna=False).to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "# 2. Data Quality Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_1",
   "metadata": {},
   "source": [
    "## 2.1 NO_DATA ÌåêÏ†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "no_data_gate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NO_DATA Gate (v3) ===\n",
      "NO_DATA: 1,705 / 9,057 (18.8%)\n",
      "  - quality_fail(LOW_CONF): 355\n",
      "  - risk_used NaN: 1,705\n",
      "  - baseline_ready False & early_ready False: 1,468\n"
     ]
    }
   ],
   "source": [
    "df = df.copy()\n",
    "\n",
    "# (1) ÌíàÏßà Ïã§Ìå®: FE/QCÍ∞Ä LOW_CONFÎ©¥ Î¨¥Ï°∞Í±¥ Î∂ÑÏÑù Î∂àÍ∞Ä\n",
    "df[\"quality_fail\"] = (df[\"quality_state\"] == \"LOW_CONF\")\n",
    "\n",
    "# (2) Î∂ÑÏÑù Í∞ÄÎä•(ÏµúÏÜåÏïà):\n",
    "# - quality_fail ÏïÑÎãò\n",
    "# - risk_used Ï°¥Ïû¨\n",
    "# - baseline_ready or early_ready (Îëò Îã§ ÏóÜÏúºÎ©¥ Î™®Îç∏ Ï†êÏàò Ïã†Î¢∞ÎèÑ Î∂ÄÏ°±)\n",
    "df[\"analysis_ready\"] = (\n",
    "    (~df[\"quality_fail\"]) &\n",
    "    (df[\"risk_used\"].notna()) &\n",
    "    (df[\"baseline_ready\"] | df[\"early_ready\"])\n",
    ")\n",
    "\n",
    "# (3) ÏµúÏ¢Ö NO_DATA: Î∂ÑÏÑù Î∂àÍ∞ÄÎ©¥ NO_DATA\n",
    "df[\"is_no_data\"] = ~df[\"analysis_ready\"]\n",
    "\n",
    "print(\"=== NO_DATA Gate (v3) ===\")\n",
    "print(f\"NO_DATA: {df['is_no_data'].sum():,} / {len(df):,} ({df['is_no_data'].mean():.1%})\")\n",
    "print(f\"  - quality_fail(LOW_CONF): {df['quality_fail'].sum():,}\")\n",
    "print(f\"  - risk_used NaN: {df['risk_used'].isna().sum():,}\")\n",
    "print(f\"  - baseline_ready False & early_ready False: {((~df['baseline_ready']) & (~df['early_ready'])).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_2",
   "metadata": {},
   "source": [
    "## 2.2 Î∂ÑÏÑù Í∞ÄÎä• ÎßàÏä§ÌÅ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analysis_mask",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Analysis OK: 7,352 / 9,057 (81.2%)\n"
     ]
    }
   ],
   "source": [
    "df[\"analysis_ok\"] = df[\"analysis_ready\"]\n",
    "print(f\"‚úÖ Analysis OK: {df['analysis_ok'].sum():,} / {len(df):,} ({df['analysis_ok'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "# 3. Risk Band & Base State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3_1",
   "metadata": {},
   "source": [
    "## 3.1 Risk Band Í≥ÑÏÇ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "risk_band",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Risk Band Distribution ===\n",
      "risk_band\n",
      "SAFE      6102\n",
      "WATCH      696\n",
      "SEVERE     334\n",
      "ALERT      220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Risk score stats (analysis_ok):\n",
      "count    7352.000000\n",
      "mean        0.361768\n",
      "std         0.135779\n",
      "min         0.058131\n",
      "25%         0.277076\n",
      "50%         0.329585\n",
      "75%         0.404437\n",
      "max         0.966379\n",
      "Name: risk_used, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_risk_band(risk: float) -> str:\n",
    "    \"\"\"risk_usedÎ•º bandÎ°ú Î≥ÄÌôò\"\"\"\n",
    "    if pd.isna(risk):\n",
    "        return \"UNKNOWN\"\n",
    "    if risk < RISK_LOW:\n",
    "        return \"SAFE\"\n",
    "    elif risk < RISK_ALERT:\n",
    "        return \"WATCH\"\n",
    "    elif risk < RISK_SEVERE:\n",
    "        return \"ALERT\"\n",
    "    else:\n",
    "        return \"SEVERE\"\n",
    "\n",
    "df[\"risk_band\"] = df[\"risk_used\"].apply(get_risk_band)\n",
    "\n",
    "print(\"=== Risk Band Distribution ===\")\n",
    "print(df.loc[df[\"analysis_ok\"], \"risk_band\"].value_counts())\n",
    "print(\"\\nRisk score stats (analysis_ok):\")\n",
    "print(df.loc[df[\"analysis_ok\"], \"risk_used\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3_2",
   "metadata": {},
   "source": [
    "## 3.2 Base State Îß§Ìïë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "base_state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ base_state Ï†úÍ±∞ (pattern_stateÎ°ú ÌÜµÌï©)\n"
     ]
    }
   ],
   "source": [
    "# [v3] base_state Ï†úÍ±∞ ‚Äî determine_cat_stateÏóêÏÑú pattern_stateÎßå ÏÇ¨Ïö©ÌïòÎØÄÎ°ú Î∂àÌïÑÏöî\n",
    "# ÏÉÅÌÉú Í≤∞Ï†ïÏùÄ pattern_state(Í∑∏Î£πÎ≥Ñ Z Í∏∞Î∞ò)Í∞Ä Îã¥Îãπ\n",
    "print(\"‚úÖ base_state Ï†úÍ±∞ (pattern_stateÎ°ú ÌÜµÌï©)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "# 4. Context Override"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4_1",
   "metadata": {},
   "source": [
    "## 4.1 TRAVEL Ï≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "travel_override",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAVEL Override ===\n",
      "TRAVEL: 0 / 9,057 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# TRAVEL flagÍ∞Ä ÏûàÏúºÎ©¥ Î¨¥Ï°∞Í±¥ TRAVEL\n",
    "travel_mask = df['travel_flag'].fillna(False)\n",
    "\n",
    "df['is_travel'] = travel_mask\n",
    "\n",
    "print(f\"=== TRAVEL Override ===\")\n",
    "print(f\"TRAVEL: {travel_mask.sum():,} / {len(df):,} ({travel_mask.mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "# 5. Analysis-Level State (Top-Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_1",
   "metadata": {},
   "source": [
    "## 5.1 Top-Z Feature Ï∂îÏ∂ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "topz_function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top-Z Feature Extraction ===\n",
      "Top-Z features (top 10):\n",
      "top_z_feature\n",
      "Notif_z                    1001\n",
      "daily_event_cnt_drift_z     916\n",
      "UserAct_z                   811\n",
      "Screen_z                    765\n",
      "gap_max_drift_z             757\n",
      "overnight_gap_z             613\n",
      "hour_entropy_z              519\n",
      "gap_max_z                   411\n",
      "gap_long_ratio_z            354\n",
      "night_ratio_z               276\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Analysis-Level State (Top-Z)\n",
    "# 5.1 Top-Z Feature Ï∂îÏ∂ú (analysis_okÏóêÏÑúÎßå)\n",
    "z_cols = [c for c in df.columns if c.endswith(\"_z\") and not c.endswith(\"_z_early\")]\n",
    "\n",
    "df[\"top_z_feature\"] = \"none\"\n",
    "df[\"top_z_value\"] = 0.0\n",
    "\n",
    "def get_top_z_feature(row: pd.Series, z_cols: List[str]) -> Tuple[str, float]:\n",
    "    zvals = row[z_cols]\n",
    "    zvals = zvals[pd.notna(zvals)]\n",
    "    if len(zvals) == 0:\n",
    "        return (\"none\", 0.0)\n",
    "    # abs ÏµúÎåÄ\n",
    "    top_col = (zvals.abs()).idxmax()\n",
    "    return (top_col, float(zvals[top_col]))\n",
    "\n",
    "mask = df[\"analysis_ok\"]\n",
    "topz_results = df.loc[mask].apply(lambda r: get_top_z_feature(r, z_cols), axis=1)\n",
    "df.loc[mask, \"top_z_feature\"] = topz_results.apply(lambda x: x[0]).astype(\"string\")\n",
    "df.loc[mask, \"top_z_value\"] = topz_results.apply(lambda x: x[1]).astype(float)\n",
    "\n",
    "print(\"=== Top-Z Feature Extraction ===\")\n",
    "print(\"Top-Z features (top 10):\")\n",
    "print(df.loc[df[\"analysis_ok\"], \"top_z_feature\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_2",
   "metadata": {},
   "source": [
    "## 5.2 Ìå®ÌÑ¥Î≥Ñ ÏÉÅÌÉú ÌåêÏ†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pattern_decode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pattern State (v3: group-based) ===\n",
      "pattern_state\n",
      "STABLE      4008\n",
      "CHAOS       1322\n",
      "LETHARGY    1237\n",
      "SLEEP        785\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def decode_pattern_state(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    [v3] Í∑∏Î£πÎ≥Ñ ÎåÄÌëú Z + Top-Z feature Í∏∞Î∞ò ÏÉÅÌÉú ÌåêÏ†ï\n",
    "    \n",
    "    1Ï∞®: Í∑∏Î£π ÎåÄÌëúÍ∞í(z_rhythm_rep, z_core_rep, z_gap_rep)ÏúºÎ°ú Ïñ¥Îñ§ ÏòÅÏó≠Ïù¥ Ïù¥ÏÉÅÌïúÏßÄ ÌåêÎã®\n",
    "    2Ï∞®: Top-Z featureÎ°ú ÏÑ∏Î∂Ä ÌôïÏù∏ (fallback)\n",
    "    \"\"\"\n",
    "    top_feature = row[\"top_z_feature\"]\n",
    "    top_value   = row[\"top_z_value\"]\n",
    "    \n",
    "    # Í∑∏Î£π ÎåÄÌëúÍ∞í ÏùΩÍ∏∞ (ÏóÜÏúºÎ©¥ 0)\n",
    "    rhythm_rep = float(row.get(\"z_rhythm_rep\", 0) or 0)\n",
    "    core_rep   = float(row.get(\"z_core_rep\", 0) or 0)\n",
    "    gap_rep    = float(row.get(\"z_gap_rep\", 0) or 0)\n",
    "    session_rep= float(row.get(\"z_session_rep\", 0) or 0)\n",
    "    \n",
    "    # Í∑∏Î£π ÎåÄÌëúÍ∞í Í∏∞Î∞ò ÌõÑÎ≥¥ ÏàòÏßë (threshold Ïù¥ÏÉÅÏù∏ Í∑∏Î£πÎì§)\n",
    "    candidates = {}\n",
    "    if rhythm_rep >= GROUP_Z_THRESHOLD:\n",
    "        candidates[\"SLEEP\"] = rhythm_rep\n",
    "    if core_rep >= GROUP_Z_THRESHOLD:\n",
    "        # LETHARGYÎäî ÌôúÎèô 'Í∞êÏÜå'Ïùº ÎïåÎßå ‚Üí top_zÍ∞Ä ÏùåÏàòÏù∏ÏßÄ ÌôïÏù∏\n",
    "        if top_feature in LETHARGY_FEATURES and top_value < 0:\n",
    "            candidates[\"LETHARGY\"] = core_rep\n",
    "        elif top_feature not in LETHARGY_FEATURES:\n",
    "            # coreÍ∞Ä ÎÜíÏßÄÎßå top_zÍ∞Ä lethargy ÌîºÏ≤òÍ∞Ä ÏïÑÎãå Í≤ΩÏö∞ ‚Üí ÌôúÎèô Í∏âÏ¶ùÏùº Ïàò ÏûàÏùå\n",
    "            pass\n",
    "        else:\n",
    "            candidates[\"LETHARGY\"] = core_rep\n",
    "    if gap_rep >= GROUP_Z_THRESHOLD:\n",
    "        candidates[\"CHAOS\"] = gap_rep\n",
    "    \n",
    "    # ÌõÑÎ≥¥Í∞Ä ÏûàÏúºÎ©¥ Í∞ÄÏû• ÎÜíÏùÄ Í∑∏Î£πÏúºÎ°ú\n",
    "    if candidates:\n",
    "        return max(candidates, key=candidates.get)\n",
    "    \n",
    "    # fallback: Í∑∏Î£π ÎåÄÌëúÍ∞íÏù¥ ÏóÜÏúºÎ©¥ Í∏∞Ï°¥ Top-Z Î°úÏßÅ\n",
    "    if abs(top_value) < Z_THRESHOLD:\n",
    "        return \"STABLE\"\n",
    "    \n",
    "    if top_feature in SLEEP_FEATURES:\n",
    "        return \"SLEEP\"\n",
    "    if top_feature in LETHARGY_FEATURES:\n",
    "        return \"LETHARGY\" if top_value < 0 else \"STABLE\"\n",
    "    if top_feature in CHAOS_FEATURES:\n",
    "        return \"CHAOS\"\n",
    "    \n",
    "    return \"STABLE\"\n",
    "\n",
    "\n",
    "df[\"pattern_state\"] = \"UNKNOWN\"\n",
    "df.loc[df[\"analysis_ok\"], \"pattern_state\"] = df.loc[df[\"analysis_ok\"]].apply(decode_pattern_state, axis=1)\n",
    "\n",
    "print(\"=== Pattern State (v3: group-based) ===\")\n",
    "print(df.loc[df[\"analysis_ok\"], \"pattern_state\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_3",
   "metadata": {},
   "source": [
    "## 5.3 ÏµúÏ¢Ö Cat State Í≤∞Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "final_cat_state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Cat State ===\n",
      "cat_state\n",
      "STABLE      4008\n",
      "NO_DATA     1705\n",
      "CHAOS       1322\n",
      "LETHARGY    1237\n",
      "SLEEP        785\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution:\n",
      "  STABLE      : 4,008 ( 44.3%)\n",
      "  SLEEP       :   785 (  8.7%)\n",
      "  LETHARGY    : 1,237 ( 13.7%)\n",
      "  CHAOS       : 1,322 ( 14.6%)\n",
      "  TRAVEL      :     0 (  0.0%)\n",
      "  NO_DATA     : 1,705 ( 18.8%)\n"
     ]
    }
   ],
   "source": [
    "def determine_cat_state(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Ïö∞ÏÑ†ÏàúÏúÑ Í∏∞Î∞ò ÏµúÏ¢Ö ÏÉÅÌÉú Í≤∞Ï†ï\n",
    "    \n",
    "    Priority:\n",
    "    1. NO_DATA (Îç∞Ïù¥ÌÑ∞ ÌíàÏßà)\n",
    "    2. TRAVEL (Ïª®ÌÖçÏä§Ìä∏)\n",
    "    3. Pattern state (Î∂ÑÏÑù)\n",
    "    \"\"\"\n",
    "    # 1) NO_DATA\n",
    "    if row['is_no_data']:\n",
    "        return 'NO_DATA'\n",
    "    \n",
    "    # 2) TRAVEL\n",
    "    if row['is_travel']:\n",
    "        return 'TRAVEL'\n",
    "    \n",
    "    # 3) Pattern state\n",
    "    return row['pattern_state']\n",
    "\n",
    "df['cat_state'] = df.apply(determine_cat_state, axis=1)\n",
    "\n",
    "print(\"=== Final Cat State ===\")\n",
    "print(df['cat_state'].value_counts())\n",
    "print(f\"\\nDistribution:\")\n",
    "for state in ['STABLE', 'SLEEP', 'LETHARGY', 'CHAOS', 'TRAVEL', 'NO_DATA']:\n",
    "    count = (df['cat_state'] == state).sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {state:12s}: {count:5,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "# 6. Notification Level Í≤∞Ï†ï"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6_1",
   "metadata": {},
   "source": [
    "## 6.1 Base Notify Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "base_notify",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Base Notify Level ===\n",
      "base_notify\n",
      "NONE    6798\n",
      "HIGH     334\n",
      "LOW      220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_base_notify(risk_band: str) -> str:\n",
    "    \"\"\"\n",
    "    Risk band Í∏∞Î∞ò Í∏∞Î≥∏ ÏïåÎ¶º Î†àÎ≤®\n",
    "    \"\"\"\n",
    "    if risk_band == 'SAFE':\n",
    "        return 'NONE'\n",
    "    elif risk_band == 'WATCH':\n",
    "        return 'NONE'\n",
    "    elif risk_band == 'ALERT':\n",
    "        return 'LOW'\n",
    "    elif risk_band == 'SEVERE':\n",
    "        return 'HIGH'\n",
    "    else:\n",
    "        return 'NONE'\n",
    "\n",
    "df['base_notify'] = df['risk_band'].apply(get_base_notify)\n",
    "\n",
    "print(\"=== Base Notify Level ===\")\n",
    "print(df.loc[df['analysis_ok'], 'base_notify'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6_2",
   "metadata": {},
   "source": [
    "## 6.2 Context Downshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "context_downshift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== After Context Downshift ===\n",
      "notify_after_context\n",
      "NONE    8503\n",
      "HIGH     334\n",
      "LOW      220\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def apply_context_downshift(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    ContextÏóê Îî∞Îùº ÏïåÎ¶º Î†àÎ≤® ÎÇÆÏ∂§ (v3)\n",
    "    - TRAVEL/PARTIAL/TZ ‚Üí NONE (MVP Ï†ïÏ±Ö)\n",
    "    \"\"\"\n",
    "    base = row[\"base_notify\"]\n",
    "\n",
    "    if row[\"is_travel\"]:\n",
    "        return \"NONE\"\n",
    "\n",
    "    # flag Í∏∞Î∞ò downshift (Î¨∏ÏûêÏó¥ contains Ï†úÍ±∞)\n",
    "    if bool(row.get(\"partial_flag\", False)) or bool(row.get(\"tz_flag\", False)):\n",
    "        return \"NONE\"\n",
    "\n",
    "    return base\n",
    "\n",
    "df[\"notify_after_context\"] = df.apply(apply_context_downshift, axis=1)\n",
    "\n",
    "print(\"=== After Context Downshift ===\")\n",
    "print(df[\"notify_after_context\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6_3",
   "metadata": {},
   "source": [
    "## 6.3 ÏµúÏ¢Ö Notify Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "final_notify",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Notify Level (pre-cold) ===\n",
      "notify_level\n",
      "NONE    8120\n",
      "LOW      898\n",
      "HIGH      39\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Notify rate: 10.3%\n"
     ]
    }
   ],
   "source": [
    "def determine_notify_level(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    ÏµúÏ¢Ö ÏïåÎ¶º Î†àÎ≤® Í≤∞Ï†ï (cold_start Ï†ÅÏö© Ï†Ñ)\n",
    "    - NO_DATA/TRAVELÏùÄ NONE\n",
    "    - STABLEÏùÄ NONE (MVP: ÏïàÏ†ïÏùÄ ÏïåÎ¶º ÏóÜÏùå)\n",
    "    - [v3] stable_hold_flag: ÏµúÍ∑º Ïã¨Í∞ÅÌñàÎã§Í∞Ä ÏïàÏ†ïÏúºÎ°ú ÎÇ¥Î†§Ïò® Í≤ΩÏö∞ ‚Üí LOW Ïú†ÏßÄ (Î™®ÎãàÌÑ∞ÎßÅ Í≥ÑÏÜç)\n",
    "    - Í∑∏ Ïô∏Îäî context Î∞òÏòÅ notify\n",
    "    \"\"\"\n",
    "    if row[\"cat_state\"] in [\"NO_DATA\", \"TRAVEL\"]:\n",
    "        return \"NONE\"\n",
    "    if row[\"cat_state\"] == \"STABLE\":\n",
    "        # [v3] ÏµúÍ∑º 2Ï£º ÎÇ¥ Ïã¨Í∞ÅÌñàÎçò Ïù¥Î†•Ïù¥ ÏûàÏúºÎ©¥ Î∞îÎ°ú ÏïåÎ¶ºÏùÑ ÎÅÑÏßÄ ÏïäÏùå\n",
    "        if bool(row.get(\"stable_hold_flag\", False)):\n",
    "            return \"LOW\"\n",
    "        # [v3] baseline drift: ÏÑúÏÑúÌûà ÎÇòÎπ†ÏßÄÍ≥† ÏûàÏúºÎ©¥ Z-scoreÎäî ÎÇÆÏïÑÎèÑ ÏïåÎ¶º\n",
    "        if bool(row.get(\"drift_flag\", False)):\n",
    "            return \"LOW\"\n",
    "        return \"NONE\"\n",
    "    return row[\"notify_after_context\"]\n",
    "\n",
    "df[\"notify_level\"] = df.apply(determine_notify_level, axis=1)\n",
    "\n",
    "print(\"=== Final Notify Level (pre-cold) ===\")\n",
    "print(df[\"notify_level\"].value_counts())\n",
    "print(f\"\\nNotify rate: {(df['notify_level'] != 'NONE').mean():.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "# 7. Cold-Start Policy Ï†ÅÏö©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7_1",
   "metadata": {},
   "source": [
    "## 7.1 StageÎ≥Ñ ÏïåÎ¶º Ï°∞Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cold_start",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== After Cold-Start Policy ===\n",
      "notify_final\n",
      "NONE    8120\n",
      "LOW      933\n",
      "HIGH       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "By stage:\n",
      "  ONBOARD     : {'NONE': 1346}\n",
      "  WARMUP      : {'NONE': 1339}\n",
      "  SEMI_READY  : {'NONE': 1891, 'LOW': 395}\n",
      "  READY       : {'NONE': 3544, 'LOW': 538, 'HIGH': 4}\n"
     ]
    }
   ],
   "source": [
    "def apply_cold_start_policy(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Cold-start stageÏóê Îî∞Îùº ÏïåÎ¶º ÏñµÏ†ú\n",
    "    \n",
    "    ONBOARD/WARMUP ‚Üí NONE\n",
    "    SEMI_READY ‚Üí HIGHÎßå LOWÎ°ú\n",
    "    READY ‚Üí Í∑∏ÎåÄÎ°ú\n",
    "    \"\"\"\n",
    "    stage = row['cold_stage']\n",
    "    notify = row['notify_level']\n",
    "    \n",
    "    if pd.isna(stage):\n",
    "        return notify\n",
    "    \n",
    "    stage = str(stage).upper()\n",
    "    \n",
    "    if stage in ['ONBOARD', 'WARMUP']:\n",
    "        return 'NONE'\n",
    "    elif stage == 'SEMI_READY':\n",
    "        if notify == 'HIGH':\n",
    "            return 'LOW'\n",
    "        return notify\n",
    "    else:  # READY\n",
    "        return notify\n",
    "\n",
    "df['notify_final'] = df.apply(apply_cold_start_policy, axis=1)\n",
    "\n",
    "print(\"=== After Cold-Start Policy ===\")\n",
    "print(df['notify_final'].value_counts())\n",
    "print(f\"\\nBy stage:\")\n",
    "for stage in ['ONBOARD', 'WARMUP', 'SEMI_READY', 'READY']:\n",
    "    stage_df = df[df['cold_stage'] == stage]\n",
    "    if len(stage_df) > 0:\n",
    "        notify_dist = stage_df['notify_final'].value_counts().to_dict()\n",
    "        print(f\"  {stage:12s}: {notify_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8",
   "metadata": {},
   "source": [
    "# 8. Output Assembly & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8_1",
   "metadata": {},
   "source": [
    "## 8.1 Decoder Quality ÌåêÏ†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "decoder_quality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decoder Quality ===\n",
      "decoder_quality\n",
      "OK          7352\n",
      "NO_DATA     1350\n",
      "LOW_CONF     355\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_decoder_quality(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Decoder Ï≤òÎ¶¨ ÌíàÏßà ÌëúÏãú\n",
    "    \"\"\"\n",
    "    if row['cat_state'] == 'NO_DATA':\n",
    "        if row['quality_state'] == 'LOW_CONF':\n",
    "            return 'LOW_CONF'\n",
    "        else:\n",
    "            return 'NO_DATA'\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "df['decoder_quality'] = df.apply(get_decoder_quality, axis=1)\n",
    "\n",
    "print(\"=== Decoder Quality ===\")\n",
    "print(df['decoder_quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8_2",
   "metadata": {},
   "source": [
    "## 8.2 ÏµúÏ¢Ö Output ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "output_assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Output Shape ===\n",
      "Rows: 9,057\n",
      "Columns: 11\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>date</th>\n",
       "      <th>cat_state</th>\n",
       "      <th>notify_level</th>\n",
       "      <th>decoder_quality</th>\n",
       "      <th>risk_used</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>final_risk</th>\n",
       "      <th>risk_band</th>\n",
       "      <th>top_z_feature</th>\n",
       "      <th>top_z_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-22</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NO_DATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u072142</td>\n",
       "      <td>2016-06-23</td>\n",
       "      <td>STABLE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.610378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610378</td>\n",
       "      <td>ALERT</td>\n",
       "      <td>gap_max_drift_z</td>\n",
       "      <td>1.505851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uuid        date cat_state notify_level decoder_quality  risk_used  \\\n",
       "0  u072142  2016-06-19   NO_DATA         NONE         NO_DATA        NaN   \n",
       "1  u072142  2016-06-20   NO_DATA         NONE         NO_DATA        NaN   \n",
       "2  u072142  2016-06-21   NO_DATA         NONE         NO_DATA        NaN   \n",
       "3  u072142  2016-06-22   NO_DATA         NONE         NO_DATA        NaN   \n",
       "4  u072142  2016-06-23    STABLE         NONE              OK   0.610378   \n",
       "\n",
       "   risk_score  final_risk risk_band    top_z_feature  top_z_value  \n",
       "0         NaN         NaN   UNKNOWN             none     0.000000  \n",
       "1         NaN         NaN   UNKNOWN             none     0.000000  \n",
       "2         NaN         NaN   UNKNOWN             none     0.000000  \n",
       "3         NaN         NaN   UNKNOWN             none     0.000000  \n",
       "4         NaN    0.610378     ALERT  gap_max_drift_z     1.505851  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ï∂úÎ†• Ïª¨Îüº Ï†ïÏùò\n",
    "OUTPUT_COLS = [\n",
    "    \"uuid\",\n",
    "    \"date\",\n",
    "    \"cat_state\",\n",
    "    \"notify_level\",\n",
    "    \"decoder_quality\",\n",
    "    # ÎîîÎ≤ÑÍ∑∏Ïö©\n",
    "    \"risk_used\",\n",
    "    \"risk_score\",\n",
    "    \"final_risk\",\n",
    "    \"risk_band\",\n",
    "    \"top_z_feature\",\n",
    "    \"top_z_value\",\n",
    "]\n",
    "\n",
    "# notify_levelÏùÄ notify_final ÏÇ¨Ïö©\n",
    "output_df = df.copy()\n",
    "output_df['notify_level'] = output_df['notify_final']\n",
    "\n",
    "# ÎÇ†Ïßú ÌòïÏãù Î≥ÄÌôò\n",
    "output_df['date'] = pd.to_datetime(output_df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# ÏµúÏ¢Ö ÏÑ†ÌÉù\n",
    "final_output = output_df[OUTPUT_COLS].copy()\n",
    "\n",
    "print(\"=== Output Shape ===\")\n",
    "print(f\"Rows: {len(final_output):,}\")\n",
    "print(f\"Columns: {len(final_output.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "final_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8_3",
   "metadata": {},
   "source": [
    "## 8.3 Ï§ëÎ≥µÌÇ§ Ï≤¥ÌÅ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "duplicate_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No duplicates (uuid + date unique)\n"
     ]
    }
   ],
   "source": [
    "# uuid + date Ï§ëÎ≥µ Ï≤¥ÌÅ¨\n",
    "duplicates = final_output.duplicated(subset=['uuid', 'date'], keep=False)\n",
    "\n",
    "if duplicates.any():\n",
    "    print(f\"‚ö†Ô∏è WARNING: {duplicates.sum()} duplicate rows found\")\n",
    "    print(final_output[duplicates].head())\n",
    "else:\n",
    "    print(\"‚úÖ No duplicates (uuid + date unique)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8_4",
   "metadata": {},
   "source": [
    "## 8.4 State Î∂ÑÌè¨ Î¶¨Ìè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "state_report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üìä DECODER OUTPUT SUMMARY\n",
      "==================================================\n",
      "\n",
      "[Cat State Distribution]\n",
      "  üò∫ STABLE      : 4,008 ( 44.3%)\n",
      "  ‚ö´ NO_DATA     : 1,705 ( 18.8%)\n",
      "  üòµ CHAOS       : 1,322 ( 14.6%)\n",
      "  üòæ LETHARGY    : 1,237 ( 13.7%)\n",
      "  üò¥ SLEEP       :   785 (  8.7%)\n",
      "\n",
      "[Notify Level Distribution]\n",
      "  NONE    : 8,120 ( 89.7%)\n",
      "  LOW     :   933 ( 10.3%)\n",
      "  HIGH    :     4 (  0.0%)\n",
      "\n",
      "[Decoder Quality]\n",
      "  OK          : 7,352 ( 81.2%)\n",
      "  NO_DATA     : 1,350 ( 14.9%)\n",
      "  LOW_CONF    :   355 (  3.9%)\n",
      "\n",
      "[Risk Band (analysis_ok only)]\n",
      "  SAFE    : 6,102 ( 83.0%)\n",
      "  WATCH   :   696 (  9.5%)\n",
      "  SEVERE  :   334 (  4.5%)\n",
      "  ALERT   :   220 (  3.0%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"üìä DECODER OUTPUT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n[Cat State Distribution]\")\n",
    "state_dist = final_output['cat_state'].value_counts()\n",
    "for state, count in state_dist.items():\n",
    "    pct = count / len(final_output) * 100\n",
    "    emoji = {'STABLE': 'üò∫', 'SLEEP': 'üò¥', 'LETHARGY': 'üòæ', \n",
    "             'CHAOS': 'üòµ', 'TRAVEL': 'üß≥', 'NO_DATA': '‚ö´'}.get(state, '')\n",
    "    print(f\"  {emoji} {state:12s}: {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n[Notify Level Distribution]\")\n",
    "notify_dist = final_output['notify_level'].value_counts()\n",
    "for level, count in notify_dist.items():\n",
    "    pct = count / len(final_output) * 100\n",
    "    print(f\"  {level:8s}: {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n[Decoder Quality]\")\n",
    "quality_dist = final_output['decoder_quality'].value_counts()\n",
    "for qual, count in quality_dist.items():\n",
    "    pct = count / len(final_output) * 100\n",
    "    print(f\"  {qual:12s}: {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n[Risk Band (analysis_ok only)]\")\n",
    "risk_ok = final_output[final_output['decoder_quality'] == 'OK']\n",
    "risk_dist = risk_ok['risk_band'].value_counts()\n",
    "for band, count in risk_dist.items():\n",
    "    pct = count / len(risk_ok) * 100 if len(risk_ok) > 0 else 0\n",
    "    print(f\"  {band:8s}: {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8_5",
   "metadata": {},
   "source": [
    "## 8.5 ÌååÏùº Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "save_output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚úÖ DECODER OUTPUT SAVED\n",
      "==================================================\n",
      "Path: C:\\Users\\DS3\\Desktop\\amz\\artifacts\\decoder\\state_out_v3.csv\n",
      "Rows: 9,057\n",
      "Users: 342\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = Path(\"../artifacts/decoder\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_PATH = OUT_DIR / \"state_out_v3.csv\"\n",
    "\n",
    "final_output.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"‚úÖ DECODER OUTPUT SAVED\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Path: {OUT_PATH.resolve()}\")\n",
    "print(f\"Rows: {len(final_output):,}\")\n",
    "print(f\"Users: {final_output['uuid'].nunique()}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section9",
   "metadata": {},
   "source": [
    "# 9. Decoder Quality Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section9_1",
   "metadata": {},
   "source": [
    "## 9.1 ÏÉÅÌÉú Ï†ÑÌôò Îß§Ìä∏Î¶≠Ïä§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "transition_matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== State Transition Matrix ===\n",
      "cat_state   CHAOS  LETHARGY  NO_DATA  SLEEP  STABLE   All\n",
      "prev_state                                               \n",
      "CHAOS         307       210       35    171     530  1253\n",
      "LETHARGY      245       342       13    156     439  1195\n",
      "NO_DATA        36        11     1241     17     377  1682\n",
      "SLEEP         193       120       25    114     267   719\n",
      "STABLE        541       554       49    327    2395  3866\n",
      "All          1322      1237     1363    785    4008  8715\n",
      "\n",
      "=== Top 10 Transitions ===\n",
      "prev_state  cat_state\n",
      "STABLE      STABLE       2395\n",
      "NO_DATA     NO_DATA      1241\n",
      "STABLE      LETHARGY      554\n",
      "            CHAOS         541\n",
      "CHAOS       STABLE        530\n",
      "LETHARGY    STABLE        439\n",
      "NO_DATA     STABLE        377\n",
      "LETHARGY    LETHARGY      342\n",
      "STABLE      SLEEP         327\n",
      "CHAOS       CHAOS         307\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ÎÇ†ÏßúÏàú Ï†ïÎ†¨\n",
    "transition_df = final_output.sort_values(['uuid', 'date']).copy()\n",
    "\n",
    "# Ïù¥Ï†Ñ ÏÉÅÌÉú\n",
    "transition_df['prev_state'] = transition_df.groupby('uuid')['cat_state'].shift(1)\n",
    "\n",
    "# Ï†ÑÌôòÎßå Ï∂îÏ∂ú\n",
    "transitions = transition_df[transition_df['prev_state'].notna()].copy()\n",
    "\n",
    "if len(transitions) > 0:\n",
    "    print(\"=== State Transition Matrix ===\")\n",
    "    transition_matrix = pd.crosstab(\n",
    "        transitions['prev_state'], \n",
    "        transitions['cat_state'],\n",
    "        margins=True\n",
    "    )\n",
    "    print(transition_matrix)\n",
    "    \n",
    "    # Ï†ÑÌôò ÎπàÎèÑ (ÏÉÅÏúÑ 10Í∞ú)\n",
    "    print(\"\\n=== Top 10 Transitions ===\")\n",
    "    trans_counts = transitions.groupby(['prev_state', 'cat_state']).size().sort_values(ascending=False)\n",
    "    print(trans_counts.head(10))\n",
    "else:\n",
    "    print(\"No transitions found (single-day users)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section9_2",
   "metadata": {},
   "source": [
    "## 9.2 Top-Z Feature ÌÜµÍ≥Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "topz_stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top-Z Feature by Cat State ===\n",
      "\n",
      "SLEEP:\n",
      "top_z_feature\n",
      "hour_entropy_z             333\n",
      "night_ratio_z              191\n",
      "Notif_z                    134\n",
      "overnight_gap_z             46\n",
      "daily_event_cnt_drift_z     44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "LETHARGY:\n",
      "top_z_feature\n",
      "UserAct_z            594\n",
      "Screen_z             477\n",
      "daily_event_cnt_z    166\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CHAOS:\n",
      "top_z_feature\n",
      "overnight_gap_z            349\n",
      "Notif_z                    282\n",
      "gap_max_z                  273\n",
      "gap_long_ratio_z           182\n",
      "daily_event_cnt_drift_z     82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "STABLE:\n",
      "top_z_feature\n",
      "daily_event_cnt_drift_z    790\n",
      "gap_max_drift_z            743\n",
      "Notif_z                    585\n",
      "Screen_z                   265\n",
      "overnight_gap_z            218\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Î∂ÑÏÑù Í∞ÄÎä•Ìïú ÎÇ†Îßå\n",
    "analysis_df = final_output[final_output['decoder_quality'] == 'OK'].copy()\n",
    "\n",
    "if len(analysis_df) > 0:\n",
    "    print(\"=== Top-Z Feature by Cat State ===\")\n",
    "    for state in ['SLEEP', 'LETHARGY', 'CHAOS', 'STABLE']:\n",
    "        state_df = analysis_df[analysis_df['cat_state'] == state]\n",
    "        if len(state_df) > 0:\n",
    "            print(f\"\\n{state}:\")\n",
    "            top_features = state_df['top_z_feature'].value_counts().head(5)\n",
    "            print(top_features)\n",
    "else:\n",
    "    print(\"No analysis_ok data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section9_3",
   "metadata": {},
   "source": [
    "## 9.3 Ïú†Ï†ÄÎ≥Ñ ÏÉÅÌÉú Î∂ÑÌè¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "user_state_dist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== User Mode State Distribution ===\n",
      "cat_state\n",
      "STABLE      307\n",
      "NO_DATA      25\n",
      "CHAOS         6\n",
      "LETHARGY      3\n",
      "SLEEP         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Notification Coverage ===\n",
      "Users with notifications: 229 / 342 (67.0%)\n"
     ]
    }
   ],
   "source": [
    "# Ïú†Ï†ÄÎ≥Ñ Í∞ÄÏû• ÎßéÏùÄ ÏÉÅÌÉú\n",
    "user_mode_state = final_output.groupby('uuid')['cat_state'].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else 'UNKNOWN')\n",
    "\n",
    "print(\"=== User Mode State Distribution ===\")\n",
    "print(user_mode_state.value_counts())\n",
    "\n",
    "# ÏïåÎ¶º Î∞õÏùÄ Ïú†Ï†Ä ÎπÑÏú®\n",
    "users_with_notify = final_output[final_output['notify_level'] != 'NONE']['uuid'].nunique()\n",
    "total_users = final_output['uuid'].nunique()\n",
    "\n",
    "print(f\"\\n=== Notification Coverage ===\")\n",
    "print(f\"Users with notifications: {users_with_notify} / {total_users} ({users_with_notify/total_users:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b73af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
